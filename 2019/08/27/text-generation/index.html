<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon-32x32.ico?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="baidu-site-verification" content="eYmWT0dEmt">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.1',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="The first part of this resource pool summarizes the resources used to solve text generation tasks using the language model GPT2, including papers, code, demo demos, and hands-on tutorials. The second">
<meta name="keywords" content="文本生成">
<meta property="og:type" content="article">
<meta property="og:title" content="使用语言模型GPT2来解决文本生成任务">
<meta property="og:url" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/index.html">
<meta property="og:site_name" content="望江人工智库">
<meta property="og:description" content="The first part of this resource pool summarizes the resources used to solve text generation tasks using the language model GPT2, including papers, code, demo demos, and hands-on tutorials. The second">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/gpt2-sizes-hyperparameters-3.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/GPT-2_Explorer.png">
<meta property="og:image" content="https://transformer.huggingface.co/front/assets/unicorn-tweaked.svg">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/gpt-2-simple.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/grover_demo.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/Transformer_decoder_MT.jpeg">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/wikipedia-summarization.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/decoder-only-summarization.png">
<meta property="og:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/BERT_more.jpg">
<meta property="og:updated_time" content="2019-11-11T07:13:23.355Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="使用语言模型GPT2来解决文本生成任务">
<meta name="twitter:description" content="The first part of this resource pool summarizes the resources used to solve text generation tasks using the language model GPT2, including papers, code, demo demos, and hands-on tutorials. The second">
<meta name="twitter:image" content="https://yuanxiaosc.github.io/2019/08/27/text-generation/gpt2-sizes-hyperparameters-3.png">
  <link rel="canonical" href="https://yuanxiaosc.github.io/2019/08/27/text-generation/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>使用语言模型GPT2来解决文本生成任务 | 望江人工智库</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?359fbde2215e8ede98cdd58478ab2c53";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">望江人工智库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">TF-KMP</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="fa fa-search fa-fw"></i>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/yuanxiaosc" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://yuanxiaosc.github.io/2019/08/27/text-generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="袁宵">
      <meta itemprop="description" content="专注于人工智能领域研究，特别是自然语言处理。">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="望江人工智库">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">使用语言模型GPT2来解决文本生成任务

          
        </h2>

        <div class="post-meta">
		  	  
			  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
			   

              
                
              

              <time title="创建时间：2019-08-27 08:30:00" itemprop="dateCreated datePublished" datetime="2019-08-27T08:30:00+08:00">2019-08-27</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-11 15:13:23" itemprop="dateModified" datetime="2019-11-11T15:13:23+08:00">2019-11-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>The first part of this resource pool summarizes the resources used to solve text generation tasks using the language model GPT2, including papers, code, demo demos, and hands-on tutorials. The second part shows the application of GPT2 in the text generation tasks of machine translation, automatic summary generation, migration learning and music generation. Finally, the 15 major language models based on Transformer between 2018 and 2019 are compared.</p><a id="more"></a>
<p>本资源汇第一部分汇总了使用语言模型GPT2来解决文本生成任务的资源，包括论文、代码、展示demo和动手教程。第二部展示了GPT2在机器翻译、自动摘要生成、迁移学习和音乐生成这些文本生成任务上的应用。最后对比了2018-2019年间重要的基于Transformer的15个语言模型</p>
<p><img src="/2019/08/27/text-generation/gpt2-sizes-hyperparameters-3.png" alt=""></p>
<h2 id="GPT-2"><a href="#GPT-2" class="headerlink" title="GPT-2"></a>GPT-2</h2><p>GPT-2 is a large transformer-based language model released by OpenAI in February 2019. It contains 1.5 billion parameters and is trained on a 8 million web dataset. According to reports, the model is a direct extension of the GPT model, training on more than 10 times the amount of data, the parameter amount is also 10 times more. In terms of performance, the model is capable of producing coherent text paragraphs and achieves SOTA performance on many language modeling benchmarks. Moreover, the model can perform preliminary reading comprehension, machine translation, question and answer and automatic summarization without task-specific training.</p>
<p>GPT-2是OpenAI于2019年2月发布的基于 transformer 的大型语言模型，包含 15 亿参数、在一个 800 万网页数据集上训练而成。据介绍，该模型是对 GPT 模型的直接扩展，在超出 10 倍的数据量上进行训练，参数量也多出了 10 倍。在性能方面，该模型能够生产连贯的文本段落，在许多语言建模基准上取得了 SOTA 表现。而且该模型在没有任务特定训练的情况下，能够做到初步的阅读理解、机器翻译、问答和自动摘要。</p>
<ul>
<li>主页 OpenAI Homepage : <a href="https://openai.com/blog/better-language-models/" target="_blank" rel="noopener">Better Language Models and Their Implications</a></li>
<li>代码 Code : <a href="https://github.com/openai/gpt-2" target="_blank" rel="noopener">gpt-2</a></li>
<li>论文 OpenAI 2019 Paper : <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">Language Models are Unsupervised Multitask Learners</a></li>
</ul>
<h3 id="GPT-2-Demo"><a href="#GPT-2-Demo" class="headerlink" title="GPT-2 Demo"></a>GPT-2 Demo</h3><p>GPT-2_Explorer Demo It can give the next ten words of the possibility ranking and their corresponding probabilities according to the currently input text. You can select one of the words, then see the list of the next possible word, and so on, and finally complete one. Article.</p>
<p>GPT-2_Explorer Demo 它可以根据当前输入的文本给出可能性排名前十的下一个单词及其对应概率，你可以选择其中一个单词，然后看到下一个可能单词的列表，如此往复，最终完成一篇文章。</p>
<p><img src="/2019/08/27/text-generation/GPT-2_Explorer.png" alt=""></p>
<p><a href="https://gpt2.apps.allenai.org/?text=Joel%20is" target="_blank" rel="noopener">点击体验 Click to GPT-2 Explorer Demo</a></p>
<h3 id="Write-With-Transformer-Demo"><a href="#Write-With-Transformer-Demo" class="headerlink" title="Write With Transformer Demo"></a>Write With Transformer Demo</h3><p><img src="https://transformer.huggingface.co/front/assets/unicorn-tweaked.svg" alt=""></p>
<p><a href="https://transformer.huggingface.co/" target="_blank" rel="noopener">Write With Transformer</a></p>
<h3 id="GPT-2-elevant-articles"><a href="#GPT-2-elevant-articles" class="headerlink" title="GPT-2 elevant articles"></a>GPT-2 elevant articles</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/56865533" target="_blank" rel="noopener">效果惊人的GPT 2.0模型：它告诉了我们什么 张俊林</a></li>
<li><a href="http://www.sohu.com/a/336262203_129720" target="_blank" rel="noopener">完全图解GPT-2：看完这篇就够了（一）</a> <a href="https://www.jiqizhixin.com/articles/2019-08-26-12" target="_blank" rel="noopener">完全图解GPT-2：看完这篇就够了（二）</a></li>
<li><a href="https://jalammar.github.io/illustrated-gpt2/" target="_blank" rel="noopener">The Illustrated GPT-2 (Visualizing Transformer Language Models)</a></li>
</ul>
<h3 id="hands-on-GPT-2"><a href="#hands-on-GPT-2" class="headerlink" title="hands-on GPT-2"></a>hands-on GPT-2</h3><ul>
<li><a href="https://zhuanlan.zhihu.com/p/56869079" target="_blank" rel="noopener">GPT-2 试用总结及感想</a></li>
</ul>
<hr>
<h2 id="GPT-2-simple"><a href="#GPT-2-simple" class="headerlink" title="GPT-2-simple"></a>GPT-2-simple</h2><p>GPT-2-simple Python package to easily retrain OpenAI’s GPT-2 text-generating model on new texts.</p>
<p>GPT-2-simple Python包可以轻松地在新文本上重新训练OpenAI的GPT-2文本生成模型。</p>
<ul>
<li>代码 Code : <a href="https://github.com/minimaxir/gpt-2-simple" target="_blank" rel="noopener">gpt-2-simple</a></li>
</ul>
<h3 id="GPT-2-simple-Demo"><a href="#GPT-2-simple-Demo" class="headerlink" title="GPT-2-simple Demo"></a>GPT-2-simple Demo</h3><p>GPT-2-simple Demo Writes a follow-up story based on the current input text.<br>GPT-2-simple Demo 根据当前输入文本编写后续的故事。</p>
<p><img src="/2019/08/27/text-generation/gpt-2-simple.png" alt=""></p>
<p><a href="https://www.thisstorydoesnotexist.com/" target="_blank" rel="noopener">点击体验 Click to gpt-2-simple Demo</a></p>
<hr>
<h2 id="grover-OpenGPT-2"><a href="#grover-OpenGPT-2" class="headerlink" title="grover: OpenGPT-2"></a>grover: OpenGPT-2</h2><p>Grover is a model for Neural Fake News — both generation and detection.<br>Grover是神经虚假新闻的模型 - 生成和检测。</p>
<ul>
<li>项目主页 Project Home : <a href="https://rowanzellers.com/grover/" target="_blank" rel="noopener">Grover: A State-of-the-Art Defense against Neural Fake News</a></li>
<li>代码 Code : <a href="https://github.com/rowanz/grover" target="_blank" rel="noopener">grover</a></li>
<li>论文 2019 Paper : <a href="https://arxiv.org/abs/1905.12616" target="_blank" rel="noopener">Defending Against Neural Fake News</a></li>
</ul>
<h3 id="grover-demo"><a href="#grover-demo" class="headerlink" title="grover demo"></a>grover demo</h3><p>Generate articles based on information such as title, author, and more. Grover can also detect if text is generated by the machine.</p>
<p>根据标题、作者等信息生成文章。grover 还可以检测文本是否由机器生成。</p>
<p><img src="/2019/08/27/text-generation/grover_demo.png" alt=""></p>
<p><a href="https://grover.allenai.org" target="_blank" rel="noopener">点击体验 Click to GROVER</a></p>
<h3 id="grover-elevant-articles"><a href="#grover-elevant-articles" class="headerlink" title="grover elevant articles"></a>grover elevant articles</h3><ul>
<li><a href="https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc" target="_blank" rel="noopener">OpenGPT-2: We Replicated GPT-2 Because You Can Too</a></li>
<li><a href="https://medium.com/ai2-blog/counteracting-neural-disinformation-with-grover-6cf6690d463b" target="_blank" rel="noopener">Counteracting neural disinformation with Grover</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2019-08-24" target="_blank" rel="noopener">15亿参数的GPT-2被两个CS硕士复制出来了，没有语言建模经验，花了5万美元</a></li>
</ul>
<hr>
<h2 id="语言建模之外-Beyond-Language-Modeling"><a href="#语言建模之外-Beyond-Language-Modeling" class="headerlink" title="语言建模之外 Beyond Language Modeling"></a>语言建模之外 Beyond Language Modeling</h2><p><a href="https://jalammar.github.io/illustrated-gpt2/" target="_blank" rel="noopener">Click to read the English version</a></p>
<p>只包含解码器的 transformer （比如GPT2）不断地表现出在语言建模之外的应用前景。在许多应用程序中，这类模型已经取得了成功：机器翻译、自动摘要生成、迁移学习和音乐生成。让我们一起来回顾一下其中的一些应用。</p>
<h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p>进行翻译时，模型不需要编码器。同样的任务可以通过一个只有解码器的 transformer 来解决：</p>
<p><img src="/2019/08/27/text-generation/Transformer_decoder_MT.jpeg" alt=""></p>
<h3 id="自动摘要生成"><a href="#自动摘要生成" class="headerlink" title="自动摘要生成"></a>自动摘要生成</h3><p>这是第一个训练只包含解码器的 transformer 的任务。也就是说，该模型被训练来阅读维基百科的文章（没有目录前的开头部分），然后生成摘要。文章实际的开头部分被用作训练数据集的标签：</p>
<p><img src="/2019/08/27/text-generation/wikipedia-summarization.png" alt=""></p>
<p>论文使用维基百科的文章对模型进行了训练，训练好的模型能够生成文章的摘要：</p>
<p><img src="/2019/08/27/text-generation/decoder-only-summarization.png" alt=""></p>
<h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>在论文 <a href="https://arxiv.org/abs/1905.08836" target="_blank" rel="noopener">Sample Efficient Text Summarization Using a Single Pre-Trained Transformer</a>中，首先使用只包含解码器的 transformer 在语言建模任务中进行预训练，然后通过调优来完成摘要生成任务。结果表明，在数据有限的情况下，该方案比预训练好的编码器-解码器 transformer 得到了更好的效果。<br>GPT2 的论文也展示了对语言建模模型进行预训练后取得的摘要生成效果。</p>
<h3 id="音乐生成"><a href="#音乐生成" class="headerlink" title="音乐生成"></a>音乐生成</h3><p>音乐 <a href="https://magenta.tensorflow.org/music-transformer" target="_blank" rel="noopener">transformer</a> 采用了只包含解码器的 transformer 来生成具有丰富节奏和动感的音乐。和语言建模相似，「音乐建模」就是让模型以一种无监督的方式学习音乐，然后让它输出样本（我们此前称之为「随机工作」）。</p>
<hr>
<h2 id="了解更多基于-Transformer-的模型"><a href="#了解更多基于-Transformer-的模型" class="headerlink" title="了解更多基于 Transformer 的模型"></a>了解更多基于 Transformer 的模型</h2><p>GPT2只是基于 Transformer 的模型的沧海一粟，2018-2019年的15个重要的基于Transformer 的模型的对比可以参见 <a href="https://zhuanlan.zhihu.com/p/76912493" target="_blank" rel="noopener">后BERT时代：15个预训练模型对比分析与关键点探索</a></p>
<p><img src="/2019/08/27/text-generation/BERT_more.jpg" alt=""></p>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>本站所有文章和源码均免费开放，如您喜欢，可以请我喝杯咖啡</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatpay.jpg" alt="袁宵 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block">
        <img src="/images/alipay.jpg" alt="袁宵 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>袁宵</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://yuanxiaosc.github.io/2019/08/27/text-generation/" title="使用语言模型GPT2来解决文本生成任务">https://yuanxiaosc.github.io/2019/08/27/text-generation/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/文本生成/" rel="tag"># 文本生成</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/08/18/中文文本纠错/" rel="next" title="中文文本纠错">
                  <i class="fa fa-chevron-left"></i> 中文文本纠错
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/08/29/数据结构算法题解/" rel="prev" title="数据结构与算法题解">
                  数据结构与算法题解 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#GPT-2"><span class="nav-number">1.</span> <span class="nav-text">GPT-2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT-2-Demo"><span class="nav-number">1.1.</span> <span class="nav-text">GPT-2 Demo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Write-With-Transformer-Demo"><span class="nav-number">1.2.</span> <span class="nav-text">Write With Transformer Demo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT-2-elevant-articles"><span class="nav-number">1.3.</span> <span class="nav-text">GPT-2 elevant articles</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hands-on-GPT-2"><span class="nav-number">1.4.</span> <span class="nav-text">hands-on GPT-2</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPT-2-simple"><span class="nav-number">2.</span> <span class="nav-text">GPT-2-simple</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GPT-2-simple-Demo"><span class="nav-number">2.1.</span> <span class="nav-text">GPT-2-simple Demo</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#grover-OpenGPT-2"><span class="nav-number">3.</span> <span class="nav-text">grover: OpenGPT-2</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#grover-demo"><span class="nav-number">3.1.</span> <span class="nav-text">grover demo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#grover-elevant-articles"><span class="nav-number">3.2.</span> <span class="nav-text">grover elevant articles</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#语言建模之外-Beyond-Language-Modeling"><span class="nav-number">4.</span> <span class="nav-text">语言建模之外 Beyond Language Modeling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#机器翻译"><span class="nav-number">4.1.</span> <span class="nav-text">机器翻译</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#自动摘要生成"><span class="nav-number">4.2.</span> <span class="nav-text">自动摘要生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#迁移学习"><span class="nav-number">4.3.</span> <span class="nav-text">迁移学习</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#音乐生成"><span class="nav-number">4.4.</span> <span class="nav-text">音乐生成</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#了解更多基于-Transformer-的模型"><span class="nav-number">5.</span> <span class="nav-text">了解更多基于 Transformer 的模型</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.png"
      alt="袁宵">
  <p class="site-author-name" itemprop="name">袁宵</p>
  <div class="site-description" itemprop="description">专注于人工智能领域研究，特别是自然语言处理。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives">
        
          <span class="site-state-item-count">142</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">54</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">133</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/yuanxiaoSC" title="GitHub &rarr; https://github.com/yuanxiaoSC" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:wangzichaochaochao@gmail.com" title="E-Mail &rarr; mailto:wangzichaochaochao@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
	  

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">袁宵</span>
</div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-5d9c4b1ac4deb418" async="async"></script>
  </div>

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">全站共 400.1k 字</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  
  <script size="300" alpha="0.6" zIndex="-1" src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js"></script>
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/pisces.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>








  <script src="/js/local-search.js?v=7.4.1"></script>














  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
